{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahzad Ahsan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"Admission_Predict_Ver1.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>330</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>308</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>302</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>323</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>325</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>327</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>311</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>314</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>317</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>325</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>328</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>336</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>340</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>322</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>298</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>295</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>310</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>471</td>\n",
       "      <td>320</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>472</td>\n",
       "      <td>311</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>473</td>\n",
       "      <td>327</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>474</td>\n",
       "      <td>316</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>475</td>\n",
       "      <td>308</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>476</td>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>477</td>\n",
       "      <td>304</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>478</td>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>479</td>\n",
       "      <td>318</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>480</td>\n",
       "      <td>325</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>481</td>\n",
       "      <td>321</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>482</td>\n",
       "      <td>323</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>483</td>\n",
       "      <td>328</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>484</td>\n",
       "      <td>304</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>485</td>\n",
       "      <td>317</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>486</td>\n",
       "      <td>311</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>487</td>\n",
       "      <td>319</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>488</td>\n",
       "      <td>327</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>489</td>\n",
       "      <td>322</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>490</td>\n",
       "      <td>302</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>491</td>\n",
       "      <td>307</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>492</td>\n",
       "      <td>297</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>493</td>\n",
       "      <td>298</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>494</td>\n",
       "      <td>300</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>495</td>\n",
       "      <td>301</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "5             6        330          115                  5  4.5   3.0  9.34   \n",
       "6             7        321          109                  3  3.0   4.0  8.20   \n",
       "7             8        308          101                  2  3.0   4.0  7.90   \n",
       "8             9        302          102                  1  2.0   1.5  8.00   \n",
       "9            10        323          108                  3  3.5   3.0  8.60   \n",
       "10           11        325          106                  3  3.5   4.0  8.40   \n",
       "11           12        327          111                  4  4.0   4.5  9.00   \n",
       "12           13        328          112                  4  4.0   4.5  9.10   \n",
       "13           14        307          109                  3  4.0   3.0  8.00   \n",
       "14           15        311          104                  3  3.5   2.0  8.20   \n",
       "15           16        314          105                  3  3.5   2.5  8.30   \n",
       "16           17        317          107                  3  4.0   3.0  8.70   \n",
       "17           18        319          106                  3  4.0   3.0  8.00   \n",
       "18           19        318          110                  3  4.0   3.0  8.80   \n",
       "19           20        303          102                  3  3.5   3.0  8.50   \n",
       "20           21        312          107                  3  3.0   2.0  7.90   \n",
       "21           22        325          114                  4  3.0   2.0  8.40   \n",
       "22           23        328          116                  5  5.0   5.0  9.50   \n",
       "23           24        334          119                  5  5.0   4.5  9.70   \n",
       "24           25        336          119                  5  4.0   3.5  9.80   \n",
       "25           26        340          120                  5  4.5   4.5  9.60   \n",
       "26           27        322          109                  5  4.5   3.5  8.80   \n",
       "27           28        298           98                  2  1.5   2.5  7.50   \n",
       "28           29        295           93                  1  2.0   2.0  7.20   \n",
       "29           30        310           99                  2  1.5   2.0  7.30   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "470         471        320          110                  5  4.0   4.0  9.27   \n",
       "471         472        311          103                  3  2.0   4.0  8.09   \n",
       "472         473        327          116                  4  4.0   4.5  9.48   \n",
       "473         474        316          102                  2  4.0   3.5  8.15   \n",
       "474         475        308          105                  4  3.0   2.5  7.95   \n",
       "475         476        300          101                  3  3.5   2.5  7.88   \n",
       "476         477        304          104                  3  2.5   2.0  8.12   \n",
       "477         478        309          105                  4  3.5   2.0  8.18   \n",
       "478         479        318          103                  3  4.0   4.5  8.49   \n",
       "479         480        325          110                  4  4.5   4.0  8.96   \n",
       "480         481        321          102                  3  3.5   4.0  9.01   \n",
       "481         482        323          107                  4  3.0   2.5  8.48   \n",
       "482         483        328          113                  4  4.0   2.5  8.77   \n",
       "483         484        304          103                  5  5.0   3.0  7.92   \n",
       "484         485        317          106                  3  3.5   3.0  7.89   \n",
       "485         486        311          101                  2  2.5   3.5  8.34   \n",
       "486         487        319          102                  3  2.5   2.5  8.37   \n",
       "487         488        327          115                  4  3.5   4.0  9.14   \n",
       "488         489        322          112                  3  3.0   4.0  8.62   \n",
       "489         490        302          110                  3  4.0   4.5  8.50   \n",
       "490         491        307          105                  2  2.5   4.5  8.12   \n",
       "491         492        297           99                  4  3.0   3.5  7.81   \n",
       "492         493        298          101                  4  2.5   4.5  7.69   \n",
       "493         494        300           95                  2  3.0   1.5  8.22   \n",
       "494         495        301           99                  3  2.5   2.0  8.45   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "5           1              0.90  \n",
       "6           1              0.75  \n",
       "7           0              0.68  \n",
       "8           0              0.50  \n",
       "9           0              0.45  \n",
       "10          1              0.52  \n",
       "11          1              0.84  \n",
       "12          1              0.78  \n",
       "13          1              0.62  \n",
       "14          1              0.61  \n",
       "15          0              0.54  \n",
       "16          0              0.66  \n",
       "17          1              0.65  \n",
       "18          0              0.63  \n",
       "19          0              0.62  \n",
       "20          1              0.64  \n",
       "21          0              0.70  \n",
       "22          1              0.94  \n",
       "23          1              0.95  \n",
       "24          1              0.97  \n",
       "25          1              0.94  \n",
       "26          0              0.76  \n",
       "27          1              0.44  \n",
       "28          0              0.46  \n",
       "29          0              0.54  \n",
       "..        ...               ...  \n",
       "470         1              0.87  \n",
       "471         0              0.64  \n",
       "472         1              0.90  \n",
       "473         0              0.67  \n",
       "474         1              0.67  \n",
       "475         0              0.59  \n",
       "476         0              0.62  \n",
       "477         0              0.65  \n",
       "478         1              0.71  \n",
       "479         1              0.79  \n",
       "480         1              0.80  \n",
       "481         1              0.78  \n",
       "482         1              0.83  \n",
       "483         0              0.71  \n",
       "484         1              0.73  \n",
       "485         1              0.70  \n",
       "486         0              0.68  \n",
       "487         0              0.79  \n",
       "488         1              0.76  \n",
       "489         0              0.65  \n",
       "490         1              0.67  \n",
       "491         0              0.54  \n",
       "492         1              0.53  \n",
       "493         1              0.62  \n",
       "494         1              0.68  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[337.   118.     4.   ...   4.5    9.65   1.  ]\n",
      " [324.   107.     4.   ...   4.5    8.87   1.  ]\n",
      " [316.   104.     3.   ...   3.5    8.     1.  ]\n",
      " ...\n",
      " [330.   120.     5.   ...   5.     9.56   1.  ]\n",
      " [312.   103.     4.   ...   5.     8.43   0.  ]\n",
      " [327.   113.     4.   ...   4.5    9.04   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:,1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = dataset.copy()\n",
    "data = complete_data[:,1:8]\n",
    "labels = complete_data[:,8]\n",
    "train_data = data[:400]\n",
    "train_labels = labels[:400]\n",
    "test_data = data[400:]\n",
    "test_labels = labels[400:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(34, activation='sigmoid',input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(9, activation='sigmoid'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Step : Using K-fold Cross-Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k=4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0063 - mean_absolute_error: 0.0584\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0034 - mean_absolute_error: 0.0460\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0034 - mean_absolute_error: 0.0430\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0031 - mean_absolute_error: 0.0415\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0032 - mean_absolute_error: 0.0413\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0031 - mean_absolute_error: 0.0416\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0030 - mean_absolute_error: 0.0409\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0030 - mean_absolute_error: 0.0407\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0409\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0030 - mean_absolute_error: 0.0410\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0029 - mean_absolute_error: 0.0409\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0394\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0405\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0396\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0397\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0393\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0403\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0404\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0404\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0391\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0395\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0396\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0395\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0388\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0384\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0387\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0395\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0389\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0390\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0381\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0382\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0387\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0392\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0388\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0397\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0381\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0381\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0380\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0383\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0378\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0376\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0390\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0379\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0381\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0378\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0383\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0378\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0385\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0378\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0375\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0384\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0380\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0383\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0375\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0378\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0377\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0387\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0373\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0388\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0371\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0383\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0378\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0376\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0381\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0379\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0371\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0380\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0371\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0377\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0380\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0383\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0379\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0384\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0363\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0378\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0376\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0379\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0362\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0373\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0373\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0364\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0374\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0376\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0361\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0378\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0371\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0378\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0368\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0024 - mean_absolute_error: 0.0362\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0364\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0367\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0368\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0374\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0361\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0362\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0371\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0365\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0370\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0359\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0024 - mean_absolute_error: 0.0366\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0069 - mean_absolute_error: 0.0605\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0533\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0532\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0528\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0517\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_absolute_error: 0.0521\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0517\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0533\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0516\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0514\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0523\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0525\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0518\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0521\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0532\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0503\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0518\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0504\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0516\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0518\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0529\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0518\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0511\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0528\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0511\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0523\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0512\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0506\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0520\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0514\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0513\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0522\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0515\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0509\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0047 - mean_absolute_error: 0.0514\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 661us/step - loss: 0.0049 - mean_absolute_error: 0.0508\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 836us/step - loss: 0.0049 - mean_absolute_error: 0.0499\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0499\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0509\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 909us/step - loss: 0.0047 - mean_absolute_error: 0.0508\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 904us/step - loss: 0.0049 - mean_absolute_error: 0.0506\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0515\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0508\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0497\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 923us/step - loss: 0.0047 - mean_absolute_error: 0.0503\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0505\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0496\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0504\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0512\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0501\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0498\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0498\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0499\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0507\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0502\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0505\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0491\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0493\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0494\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0478\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0483\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0490\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0496\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0500\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0491\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0486\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0496\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0490\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0494\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0497\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0491\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0047 - mean_absolute_error: 0.0493\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0497\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0498\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0482\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0497\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0504\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0495\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0494\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0483\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0481\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0494\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0491\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0487\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0489\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0498\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0490\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0495\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0486\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0482\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0487\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0481\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0484\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0472\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0480\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0488\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0491\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0471\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0483A: 0s - loss: 0.0046 - mean_absolute_error: 0.049\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0483\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0143 - mean_absolute_error: 0.0865\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 784us/step - loss: 0.0063 - mean_absolute_error: 0.0598\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0058 - mean_absolute_error: 0.0575\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0059 - mean_absolute_error: 0.0577\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0057 - mean_absolute_error: 0.0549\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0057 - mean_absolute_error: 0.0551\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0057 - mean_absolute_error: 0.0552\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0056 - mean_absolute_error: 0.0569\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_absolute_error: 0.0553\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0056 - mean_absolute_error: 0.0551\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0056 - mean_absolute_error: 0.0556\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_absolute_error: 0.0528\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0551\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0545\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0548\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0562\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0544\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0546\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0536\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0560\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0055 - mean_absolute_error: 0.0545\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0550\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0547\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0534\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0553\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_absolute_error: 0.0532\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0534\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_absolute_error: 0.0546\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0529\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_absolute_error: 0.0537\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_absolute_error: 0.0540\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0544\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0541\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0547\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0541\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0548\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0532\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_absolute_error: 0.0536\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0531\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0529\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0536\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0531\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0517\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0531\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0053 - mean_absolute_error: 0.0524\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0532\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0532\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0519\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0520\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 995us/step - loss: 0.0052 - mean_absolute_error: 0.0527\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0525\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0533\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0515\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0518\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0535\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0513\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 787us/step - loss: 0.0051 - mean_absolute_error: 0.0534\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 907us/step - loss: 0.0050 - mean_absolute_error: 0.0518\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0531\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0521\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0509\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0052 - mean_absolute_error: 0.0518\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0521\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0051 - mean_absolute_error: 0.0526\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0512\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0516\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0052 - mean_absolute_error: 0.0522\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0520\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0510\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0522\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0520\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0512\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0515\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0531\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0513\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0518\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0512\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0516\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0524\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0522\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0514\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0517\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0524\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0516\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0518\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_error: 0.050 - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0519\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0507\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0518\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0516\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0512\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0514\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0526\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0512\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0507\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0499\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0521\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0514\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0515\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0520\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0508\n",
      "processing fold # 3\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0065 - mean_absolute_error: 0.0604\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0056 - mean_absolute_error: 0.0556\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0541\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0532\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0528\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0523\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0517\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0524\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0529\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0530\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0525\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0531\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0515\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0536\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0519\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0518\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0508\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0518\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0520\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0517\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0518\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0521\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0514\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0504\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0519\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0511\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0501\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0510\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0502\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0524\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0503\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0508\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0502\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0512\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0503\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0501\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0044 - mean_absolute_error: 0.0501\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0500\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0504\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0510\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0491\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0502\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0480\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0499\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0504\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0487\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0492\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0496\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0486\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0497\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0485\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0484\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0491\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0491\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0495\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0498\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0490\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0494\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0487\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0505\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0485\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0483\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0498\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0483\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0488\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0488\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0489\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0474\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0486\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0485\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0486\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0475\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0483\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0490\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0486\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0490\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0480\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0481\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0042 - mean_absolute_error: 0.0457\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0481\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0478\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0484\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0483\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0489\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0043 - mean_absolute_error: 0.0473\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0043 - mean_absolute_error: 0.0486\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0042 - mean_absolute_error: 0.0476\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0043 - mean_absolute_error: 0.0476\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0045 - mean_absolute_error: 0.0473\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0481\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_absolute_error: 0.0480\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0043 - mean_absolute_error: 0.0469\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0042 - mean_absolute_error: 0.0471\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0043 - mean_absolute_error: 0.0481\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0044 - mean_absolute_error: 0.0478\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0041 - mean_absolute_error: 0.0476\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0043 - mean_absolute_error: 0.0474\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0043 - mean_absolute_error: 0.0478\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0482\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0041 - mean_absolute_error: 0.0480\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "      [train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate( [train_labels[:i * num_val_samples], train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08007545739412308,\n",
       " 0.045893777012825016,\n",
       " 0.041185312271118164,\n",
       " 0.06495842635631562]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05802824325859547"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mae_histories = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All lost Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_history = history.history\n",
    "all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006495064870786488,\n",
       " 0.005601751420839302,\n",
       " 0.005266307101013392,\n",
       " 0.00521132790039303,\n",
       " 0.004995397232498734,\n",
       " 0.005181781856285142,\n",
       " 0.004823966362023598,\n",
       " 0.004976689410619611,\n",
       " 0.005240178912380173,\n",
       " 0.0049202266599727785,\n",
       " 0.005018583480552105,\n",
       " 0.00515890488178087,\n",
       " 0.004955486295441176,\n",
       " 0.005137913879774013,\n",
       " 0.0050354981092693525,\n",
       " 0.005046498702331377,\n",
       " 0.004739771950956531,\n",
       " 0.004873389373084223,\n",
       " 0.004991313581631616,\n",
       " 0.005033933537599798,\n",
       " 0.0049214674568389205,\n",
       " 0.004890870257049578,\n",
       " 0.004856623684040879,\n",
       " 0.004838062720206911,\n",
       " 0.004798334366379606,\n",
       " 0.004791673687276064,\n",
       " 0.004405544559143617,\n",
       " 0.00488122975425559,\n",
       " 0.004578418051165312,\n",
       " 0.0048834467993644284,\n",
       " 0.004759800353323994,\n",
       " 0.004716332746784211,\n",
       " 0.004828108683760822,\n",
       " 0.004832339112434406,\n",
       " 0.004713718106797652,\n",
       " 0.004580973138296779,\n",
       " 0.0043767630156234345,\n",
       " 0.004667352929355956,\n",
       " 0.0047353170903967744,\n",
       " 0.00464310096957482,\n",
       " 0.004519290692498963,\n",
       " 0.004630384474513297,\n",
       " 0.004572475304681719,\n",
       " 0.004692048877590101,\n",
       " 0.004528231223209135,\n",
       " 0.004608881839330271,\n",
       " 0.004478644864898626,\n",
       " 0.004555304247247752,\n",
       " 0.004488515449549588,\n",
       " 0.004646745690770911,\n",
       " 0.004330986738105101,\n",
       " 0.00430793863994874,\n",
       " 0.004578972358501356,\n",
       " 0.004442964130756634,\n",
       " 0.004510653525470663,\n",
       " 0.004523566896802151,\n",
       " 0.004641897901152857,\n",
       " 0.0042806371490363895,\n",
       " 0.004627683074061603,\n",
       " 0.0044982271736977945,\n",
       " 0.004436673552833715,\n",
       " 0.004374221927945439,\n",
       " 0.004428162640370215,\n",
       " 0.0043792808239181726,\n",
       " 0.004408379386893604,\n",
       " 0.004473264935580469,\n",
       " 0.004421929425275989,\n",
       " 0.00426995390893353,\n",
       " 0.004297231355368005,\n",
       " 0.004407658490730502,\n",
       " 0.004478259941161167,\n",
       " 0.004256571191278778,\n",
       " 0.0043717887809985355,\n",
       " 0.0045191277375084245,\n",
       " 0.004362457288088611,\n",
       " 0.004498582139418848,\n",
       " 0.004317501630389795,\n",
       " 0.0043355753232205176,\n",
       " 0.004176046425252658,\n",
       " 0.004256138455542289,\n",
       " 0.0044035798094538,\n",
       " 0.004477303642906776,\n",
       " 0.004270038310307373,\n",
       " 0.00431835021285643,\n",
       " 0.004279830276340775,\n",
       " 0.004286367784485918,\n",
       " 0.004249799952231186,\n",
       " 0.004308767487508713,\n",
       " 0.004474192009824615,\n",
       " 0.004287354068377134,\n",
       " 0.004409955527132089,\n",
       " 0.004258913916637977,\n",
       " 0.004165730268498085,\n",
       " 0.004271948361324019,\n",
       " 0.0043975841968547985,\n",
       " 0.0041157383079849785,\n",
       " 0.004284047604409681,\n",
       " 0.004332987121673758,\n",
       " 0.004300067359227834,\n",
       " 0.004083016798374549]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_mae_history = all_mae_histories[0]['loss']\n",
    "smooth_mae_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06043650478124619,\n",
       " 0.05562084913253784,\n",
       " 0.05410374810298284,\n",
       " 0.053242492079734804,\n",
       " 0.05275838991006215,\n",
       " 0.052315927147865295,\n",
       " 0.05174616287151972,\n",
       " 0.05237388034661611,\n",
       " 0.05294601142406464,\n",
       " 0.05304712444543838,\n",
       " 0.0524780676762263,\n",
       " 0.05310433586438497,\n",
       " 0.05146985451380412,\n",
       " 0.05362453629573186,\n",
       " 0.05185163527727127,\n",
       " 0.05184474994738897,\n",
       " 0.05076541612545649,\n",
       " 0.051756289601325986,\n",
       " 0.05200322926044464,\n",
       " 0.05169765631357829,\n",
       " 0.05177418520053228,\n",
       " 0.05213554898897807,\n",
       " 0.051378827393054965,\n",
       " 0.050381513436635335,\n",
       " 0.05194227486848831,\n",
       " 0.05109936515490214,\n",
       " 0.05013616542021433,\n",
       " 0.05102503657341004,\n",
       " 0.050197349290053046,\n",
       " 0.052417481243610384,\n",
       " 0.050294716159502664,\n",
       " 0.05077368269364039,\n",
       " 0.050183883408705394,\n",
       " 0.05117906967798869,\n",
       " 0.05026946673790614,\n",
       " 0.05010694493850072,\n",
       " 0.05005026916662852,\n",
       " 0.05002343873182932,\n",
       " 0.05043594479560852,\n",
       " 0.05100736916065216,\n",
       " 0.049071402351061506,\n",
       " 0.050184006889661154,\n",
       " 0.048019153277079264,\n",
       " 0.049948048094908395,\n",
       " 0.050433234671751655,\n",
       " 0.04868009110291799,\n",
       " 0.04919097393751144,\n",
       " 0.04962612430254618,\n",
       " 0.048557333449522656,\n",
       " 0.04970215797424316,\n",
       " 0.04850021839141846,\n",
       " 0.048392513493696845,\n",
       " 0.04911217480897903,\n",
       " 0.04909745762745539,\n",
       " 0.04947044650713603,\n",
       " 0.04977701852718989,\n",
       " 0.048987972835699715,\n",
       " 0.04936570604642232,\n",
       " 0.04870562305053075,\n",
       " 0.05047849138577779,\n",
       " 0.04852032681306203,\n",
       " 0.04834193507830302,\n",
       " 0.04981739620367686,\n",
       " 0.04830669472614924,\n",
       " 0.048839687208334606,\n",
       " 0.048783454895019535,\n",
       " 0.048897352218627926,\n",
       " 0.04739773005247116,\n",
       " 0.0486307763059934,\n",
       " 0.04852024922768275,\n",
       " 0.04858827412128448,\n",
       " 0.04751913030942281,\n",
       " 0.04832530915737152,\n",
       " 0.048997878829638165,\n",
       " 0.048558292190233866,\n",
       " 0.04899816672007243,\n",
       " 0.04802623460690181,\n",
       " 0.04813550333182017,\n",
       " 0.045693642795085906,\n",
       " 0.04806812504927317,\n",
       " 0.04781045923630396,\n",
       " 0.04838362147410711,\n",
       " 0.04829898953437805,\n",
       " 0.04892992446819941,\n",
       " 0.04734785377979279,\n",
       " 0.0485619713862737,\n",
       " 0.047645184795061746,\n",
       " 0.047630730470021566,\n",
       " 0.047278439501921336,\n",
       " 0.04811425487200419,\n",
       " 0.04800776342550914,\n",
       " 0.04689939429362615,\n",
       " 0.04713057001431783,\n",
       " 0.048118745684623716,\n",
       " 0.04775916705528895,\n",
       " 0.04761381596326828,\n",
       " 0.04741292417049408,\n",
       " 0.047811954617500305,\n",
       " 0.04817024072011312,\n",
       " 0.04796766052643458]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_mae_new_history = all_mae_histories[0]['mean_absolute_error']\n",
    "smooth_mae_new_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lines = plt.plot(range(1, len(smooth_mae_history) + 1 , ), smooth_mae_history)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(smooth_mae_new_history) + 1 ), smooth_mae_new_history)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.006495064870786488, 0.005601751420839302, 0.005266307101013392, 0.00521132790039303, 0.004995397232498734, 0.005181781856285142, 0.004823966362023598, 0.004976689410619611, 0.005240178912380173, 0.0049202266599727785, 0.005018583480552105, 0.00515890488178087, 0.004955486295441176, 0.005137913879774013, 0.0050354981092693525, 0.005046498702331377, 0.004739771950956531, 0.004873389373084223, 0.004991313581631616, 0.005033933537599798, 0.0049214674568389205, 0.004890870257049578, 0.004856623684040879, 0.004838062720206911, 0.004798334366379606, 0.004791673687276064, 0.004405544559143617, 0.00488122975425559, 0.004578418051165312, 0.0048834467993644284, 0.004759800353323994, 0.004716332746784211, 0.004828108683760822, 0.004832339112434406, 0.004713718106797652, 0.004580973138296779, 0.0043767630156234345, 0.004667352929355956, 0.0047353170903967744, 0.00464310096957482, 0.004519290692498963, 0.004630384474513297, 0.004572475304681719, 0.004692048877590101, 0.004528231223209135, 0.004608881839330271, 0.004478644864898626, 0.004555304247247752, 0.004488515449549588, 0.004646745690770911, 0.004330986738105101, 0.00430793863994874, 0.004578972358501356, 0.004442964130756634, 0.004510653525470663, 0.004523566896802151, 0.004641897901152857, 0.0042806371490363895, 0.004627683074061603, 0.0044982271736977945, 0.004436673552833715, 0.004374221927945439, 0.004428162640370215, 0.0043792808239181726, 0.004408379386893604, 0.004473264935580469, 0.004421929425275989, 0.00426995390893353, 0.004297231355368005, 0.004407658490730502, 0.004478259941161167, 0.004256571191278778, 0.0043717887809985355, 0.0045191277375084245, 0.004362457288088611, 0.004498582139418848, 0.004317501630389795, 0.0043355753232205176, 0.004176046425252658, 0.004256138455542289, 0.0044035798094538, 0.004477303642906776, 0.004270038310307373, 0.00431835021285643, 0.004279830276340775, 0.004286367784485918, 0.004249799952231186, 0.004308767487508713, 0.004474192009824615, 0.004287354068377134, 0.004409955527132089, 0.004258913916637977, 0.004165730268498085, 0.004271948361324019, 0.0043975841968547985, 0.0041157383079849785, 0.004284047604409681, 0.004332987121673758, 0.004300067359227834, 0.004083016798374549], 'mean_absolute_error': [0.06043650478124619, 0.05562084913253784, 0.05410374810298284, 0.053242492079734804, 0.05275838991006215, 0.052315927147865295, 0.05174616287151972, 0.05237388034661611, 0.05294601142406464, 0.05304712444543838, 0.0524780676762263, 0.05310433586438497, 0.05146985451380412, 0.05362453629573186, 0.05185163527727127, 0.05184474994738897, 0.05076541612545649, 0.051756289601325986, 0.05200322926044464, 0.05169765631357829, 0.05177418520053228, 0.05213554898897807, 0.051378827393054965, 0.050381513436635335, 0.05194227486848831, 0.05109936515490214, 0.05013616542021433, 0.05102503657341004, 0.050197349290053046, 0.052417481243610384, 0.050294716159502664, 0.05077368269364039, 0.050183883408705394, 0.05117906967798869, 0.05026946673790614, 0.05010694493850072, 0.05005026916662852, 0.05002343873182932, 0.05043594479560852, 0.05100736916065216, 0.049071402351061506, 0.050184006889661154, 0.048019153277079264, 0.049948048094908395, 0.050433234671751655, 0.04868009110291799, 0.04919097393751144, 0.04962612430254618, 0.048557333449522656, 0.04970215797424316, 0.04850021839141846, 0.048392513493696845, 0.04911217480897903, 0.04909745762745539, 0.04947044650713603, 0.04977701852718989, 0.048987972835699715, 0.04936570604642232, 0.04870562305053075, 0.05047849138577779, 0.04852032681306203, 0.04834193507830302, 0.04981739620367686, 0.04830669472614924, 0.048839687208334606, 0.048783454895019535, 0.048897352218627926, 0.04739773005247116, 0.0486307763059934, 0.04852024922768275, 0.04858827412128448, 0.04751913030942281, 0.04832530915737152, 0.048997878829638165, 0.048558292190233866, 0.04899816672007243, 0.04802623460690181, 0.04813550333182017, 0.045693642795085906, 0.04806812504927317, 0.04781045923630396, 0.04838362147410711, 0.04829898953437805, 0.04892992446819941, 0.04734785377979279, 0.0485619713862737, 0.047645184795061746, 0.047630730470021566, 0.047278439501921336, 0.04811425487200419, 0.04800776342550914, 0.04689939429362615, 0.04713057001431783, 0.048118745684623716, 0.04775916705528895, 0.04761381596326828, 0.04741292417049408, 0.047811954617500305, 0.04817024072011312, 0.04796766052643458]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6927 - mean_absolute_error: 0.8208\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 179us/step - loss: 0.4088 - mean_absolute_error: 0.6279\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 297us/step - loss: 0.2594 - mean_absolute_error: 0.4952\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.1606 - mean_absolute_error: 0.3844\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 91us/step - loss: 0.0924 - mean_absolute_error: 0.2842\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0491 - mean_absolute_error: 0.1993\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0242 - mean_absolute_error: 0.1320\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 220us/step - loss: 0.0132 - mean_absolute_error: 0.0957\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 155us/step - loss: 0.0080 - mean_absolute_error: 0.0732\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0058 - mean_absolute_error: 0.0608\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 206us/step - loss: 0.0046 - mean_absolute_error: 0.0537\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0039 - mean_absolute_error: 0.0490\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 146us/step - loss: 0.0033 - mean_absolute_error: 0.0466\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.0029 - mean_absolute_error: 0.0436\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 182us/step - loss: 0.0025 - mean_absolute_error: 0.0400\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 112us/step - loss: 0.0024 - mean_absolute_error: 0.0383\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 133us/step - loss: 0.0027 - mean_absolute_error: 0.0408\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 155us/step - loss: 0.0024 - mean_absolute_error: 0.0373\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 143us/step - loss: 0.0023 - mean_absolute_error: 0.0354\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 117us/step - loss: 0.0023 - mean_absolute_error: 0.0350\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0022 - mean_absolute_error: 0.0363\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 153us/step - loss: 0.0020 - mean_absolute_error: 0.0339\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 187us/step - loss: 0.0021 - mean_absolute_error: 0.0341\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 136us/step - loss: 0.0020 - mean_absolute_error: 0.0345\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 136us/step - loss: 0.0019 - mean_absolute_error: 0.0337\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 158us/step - loss: 0.0025 - mean_absolute_error: 0.0369\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.0019 - mean_absolute_error: 0.0339\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 195us/step - loss: 0.0020 - mean_absolute_error: 0.0340\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 136us/step - loss: 0.0020 - mean_absolute_error: 0.0352\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 122us/step - loss: 0.0018 - mean_absolute_error: 0.0315\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.0019 - mean_absolute_error: 0.0332\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 135us/step - loss: 0.0022 - mean_absolute_error: 0.0362\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 123us/step - loss: 0.0020 - mean_absolute_error: 0.0340\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 114us/step - loss: 0.0018 - mean_absolute_error: 0.0317\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 136us/step - loss: 0.0020 - mean_absolute_error: 0.0339\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.0017 - mean_absolute_error: 0.0316\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0019 - mean_absolute_error: 0.0323\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 211us/step - loss: 0.0018 - mean_absolute_error: 0.0326\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 148us/step - loss: 0.0019 - mean_absolute_error: 0.0329\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0020 - mean_absolute_error: 0.0332\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0019 - mean_absolute_error: 0.0342\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 108us/step - loss: 0.0019 - mean_absolute_error: 0.0339\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.0019 - mean_absolute_error: 0.0341\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0017 - mean_absolute_error: 0.0319\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 157us/step - loss: 0.0022 - mean_absolute_error: 0.0365\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 142us/step - loss: 0.0019 - mean_absolute_error: 0.0341\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 96us/step - loss: 0.0019 - mean_absolute_error: 0.0337\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0019 - mean_absolute_error: 0.0329\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0017 - mean_absolute_error: 0.0323\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 156us/step - loss: 0.0019 - mean_absolute_error: 0.0333\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 177us/step - loss: 0.0021 - mean_absolute_error: 0.0344\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 24us/step - loss: 0.0018 - mean_absolute_error: 0.0329\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 156us/step - loss: 0.0019 - mean_absolute_error: 0.0340\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0019 - mean_absolute_error: 0.0334\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 200us/step - loss: 0.0020 - mean_absolute_error: 0.0342\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 131us/step - loss: 0.0018 - mean_absolute_error: 0.0324\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0020 - mean_absolute_error: 0.0339\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0016 - mean_absolute_error: 0.0309\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 187us/step - loss: 0.0018 - mean_absolute_error: 0.0335\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 94us/step - loss: 0.0018 - mean_absolute_error: 0.0326\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 119us/step - loss: 0.0017 - mean_absolute_error: 0.0312\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0020 - mean_absolute_error: 0.0347\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 162us/step - loss: 0.0018 - mean_absolute_error: 0.0320\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0018 - mean_absolute_error: 0.0326\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 157us/step - loss: 0.0017 - mean_absolute_error: 0.0318\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 184us/step - loss: 0.0021 - mean_absolute_error: 0.0352\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0016 - mean_absolute_error: 0.0308\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 116us/step - loss: 0.0020 - mean_absolute_error: 0.0338\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 158us/step - loss: 0.0016 - mean_absolute_error: 0.0303\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0020 - mean_absolute_error: 0.0346\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.0018 - mean_absolute_error: 0.0320\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 50us/step - loss: 0.0018 - mean_absolute_error: 0.0316\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0016 - mean_absolute_error: 0.0311\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 223us/step - loss: 0.0017 - mean_absolute_error: 0.0319\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0015 - mean_absolute_error: 0.0302\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 147us/step - loss: 0.0018 - mean_absolute_error: 0.0325\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0018 - mean_absolute_error: 0.0318\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0018 - mean_absolute_error: 0.0322\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 161us/step - loss: 0.0019 - mean_absolute_error: 0.0335\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 93us/step - loss: 0.0016 - mean_absolute_error: 0.0317\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0018 - mean_absolute_error: 0.0315\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 187us/step - loss: 0.0017 - mean_absolute_error: 0.0312\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0019 - mean_absolute_error: 0.0345\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 156us/step - loss: 0.0018 - mean_absolute_error: 0.0321\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 122us/step - loss: 0.0017 - mean_absolute_error: 0.0321\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.0019 - mean_absolute_error: 0.0342\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 150us/step - loss: 0.0017 - mean_absolute_error: 0.0319\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0017 - mean_absolute_error: 0.0318\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 223us/step - loss: 0.0017 - mean_absolute_error: 0.0311\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 109us/step - loss: 0.0016 - mean_absolute_error: 0.0307\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0021 - mean_absolute_error: 0.0361\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0018 - mean_absolute_error: 0.0315\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0018 - mean_absolute_error: 0.0330\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.0016 - mean_absolute_error: 0.0302\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0019 - mean_absolute_error: 0.0337\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 148us/step - loss: 0.0016 - mean_absolute_error: 0.0302\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.0019 - mean_absolute_error: 0.0343\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 196us/step - loss: 0.0021 - mean_absolute_error: 0.0341\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 134us/step - loss: 0.0016 - mean_absolute_error: 0.0312\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.0017 - mean_absolute_error: 0.0319\n",
      "100/100 [==============================] - 0s 911us/step\n",
      "0.0017723619076423346\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(test_data, test_labels,\n",
    "epochs=100, batch_size=16, verbose=1)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_labels)\n",
    "print(test_mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.11765165 -1.22238456 -0.95202863  0.0994422  -0.50426044 -0.63623792\n",
      "  -1.09997489]\n",
      " [-0.15773222 -0.39756367 -0.95202863 -0.39776881 -0.50426044 -0.43475068\n",
      "  -1.09997489]\n",
      " [ 0.62765641  0.26229304 -0.07660001  0.0994422  -0.50426044  0.57268548\n",
      "   0.90911166]\n",
      " [ 1.15124883  1.41704229  0.79882862  0.59665321  0.05293342  1.05961296\n",
      "   0.90911166]\n",
      " [-0.50679383 -1.05742038 -0.07660001 -1.39219083 -1.06145431 -1.61009288\n",
      "   0.90911166]\n",
      " [-1.29218245 -1.38734873 -0.07660001 -0.89497982 -0.50426044 -1.92911433\n",
      "  -1.09997489]\n",
      " [ 0.4531256  -0.72749202  0.79882862 -0.39776881 -1.06145431 -0.97204997\n",
      "   0.90911166]\n",
      " [-1.64124406 -1.22238456 -0.07660001 -0.89497982  0.61012728 -1.08958419\n",
      "   0.90911166]\n",
      " [-1.72850946 -1.05742038 -0.07660001 -1.39219083  0.61012728 -1.55972107\n",
      "   0.90911166]\n",
      " [-1.46671326 -1.55231291 -1.82745726 -1.39219083 -1.06145431 -0.97204997\n",
      "  -1.09997489]\n",
      " [-1.37944785 -1.88224127 -1.82745726 -0.39776881  0.61012728 -1.7444177\n",
      "  -1.09997489]\n",
      " [-0.33226302 -2.21216962 -0.95202863 -0.89497982 -2.17584203 -0.78735334\n",
      "  -1.09997489]\n",
      " [-0.24499762 -0.8924562   0.79882862 -0.89497982 -1.61864817 -1.20711841\n",
      "   0.90911166]\n",
      " [ 0.01679859 -1.05742038 -0.07660001 -0.39776881 -1.61864817 -1.10637479\n",
      "   0.90911166]\n",
      " [ 0.3658602   0.42725722  0.79882862  0.0994422   0.61012728 -0.41796008\n",
      "   0.90911166]\n",
      " [ 0.88945262 -0.23259949  0.79882862  0.59665321  1.16732114  0.25366403\n",
      "   0.90911166]\n",
      " [-0.15773222 -0.56252785 -0.07660001  0.59665321 -1.06145431 -0.83772515\n",
      "  -1.09997489]\n",
      " [-0.07046681 -0.72749202 -0.07660001  0.0994422  -1.61864817 -1.54293046\n",
      "  -1.09997489]\n",
      " [-0.68132463  0.5922214  -0.95202863 -0.89497982  0.61012728 -0.95525937\n",
      "  -1.09997489]\n",
      " [-0.76859003 -0.8924562  -0.95202863 -1.39219083  0.05293342 -1.03921238\n",
      "   0.90911166]\n",
      " [-1.55397866 -1.22238456 -0.07660001 -1.39219083 -0.50426044 -1.97948614\n",
      "  -1.09997489]\n",
      " [ 0.3658602   0.75718558 -0.07660001 -0.39776881  1.16732114  0.58947609\n",
      "   0.90911166]\n",
      " [ 0.4531256   0.75718558  0.79882862  0.0994422  -1.06145431  0.70701031\n",
      "   0.90911166]\n",
      " [ 1.50031044  1.91193482  1.67425725  1.09386422  1.724515    1.58012165\n",
      "   0.90911166]\n",
      " [ 0.71492181  1.08711393  1.67425725  0.59665321  1.724515    1.44579683\n",
      "   0.90911166]\n",
      " [ 0.54039101  0.5922214   1.67425725  0.59665321  1.724515    2.11742094\n",
      "   0.90911166]\n",
      " [-0.41952842 -0.23259949 -0.07660001 -0.39776881  1.724515   -0.04856682\n",
      "  -1.09997489]\n",
      " [-0.59405923 -1.05742038 -0.07660001  0.0994422   1.724515    0.085758\n",
      "   0.90911166]\n",
      " [-0.07046681 -0.72749202 -0.95202863 -1.39219083  1.16732114  0.23687343\n",
      "  -1.09997489]\n",
      " [ 2.02390285  1.25207811  1.67425725  1.59107523  1.16732114  0.77417272\n",
      "   0.90911166]\n",
      " [-0.50679383 -0.56252785 -0.07660001  0.59665321  0.05293342 -0.78735334\n",
      "   0.90911166]\n",
      " [ 0.2785948   0.75718558 -0.95202863  0.0994422   0.05293342  0.30403584\n",
      "   0.90911166]\n",
      " [ 0.62765641  0.75718558  0.79882862  1.09386422  0.61012728  1.04282236\n",
      "   0.90911166]\n",
      " [-0.07046681  0.5922214   0.79882862  0.59665321  1.724515   -0.09893863\n",
      "  -1.09997489]\n",
      " [-0.94312084 -0.72749202 -0.07660001  0.0994422  -0.50426044 -0.65302852\n",
      "  -1.09997489]\n",
      " [-0.68132463 -0.39756367 -0.95202863 -0.89497982  0.61012728 -1.54293046\n",
      "  -1.09997489]\n",
      " [-0.59405923  0.42725722 -1.82745726 -1.88940184  0.61012728 -2.29850759\n",
      "   0.90911166]\n",
      " [ 0.01679859 -0.23259949 -1.82745726 -1.88940184  0.05293342 -1.59330227\n",
      "   0.90911166]\n",
      " [ 0.10406399  0.42725722 -1.82745726 -0.89497982  0.05293342 -0.09893863\n",
      "   0.90911166]\n",
      " [-0.41952842 -0.39756367 -0.95202863 -1.88940184 -0.50426044 -0.23326345\n",
      "  -1.09997489]\n",
      " [-1.03038624 -0.56252785 -0.95202863 -0.89497982 -2.17584203 -1.35823383\n",
      "  -1.09997489]\n",
      " [ 1.32577963  0.75718558 -1.82745726 -1.88940184 -0.50426044  0.10254861\n",
      "   0.90911166]\n",
      " [ 1.23851423  1.41704229  0.79882862  1.09386422  1.16732114  1.41221562\n",
      "   0.90911166]\n",
      " [ 0.3658602   1.08711393  1.67425725  1.09386422  1.16732114  0.94207874\n",
      "   0.90911166]\n",
      " [ 0.62765641  0.92214975  1.67425725  0.59665321  1.724515    1.09319417\n",
      "   0.90911166]\n",
      " [ 0.97671802  1.41704229  1.67425725  1.09386422  1.724515    0.80775392\n",
      "   0.90911166]\n",
      " [ 0.88945262  1.74697064  0.79882862  1.59107523  1.724515    1.79839949\n",
      "   0.90911166]\n",
      " [ 0.2785948   0.09732886 -0.07660001  0.0994422   1.724515    0.62305729\n",
      "   0.90911166]\n",
      " [-0.41952842  0.26229304 -0.95202863 -0.89497982  0.61012728  0.70701031\n",
      "  -1.09997489]\n",
      " [-0.15773222 -1.05742038 -0.07660001  0.0994422   1.16732114  0.89170694\n",
      "  -1.09997489]\n",
      " [ 0.2785948   0.75718558  0.79882862 -0.39776881  1.16732114  0.43836066\n",
      "   0.90911166]\n",
      " [ 0.62765641  0.92214975  0.79882862  1.09386422  1.16732114  1.09319417\n",
      "   0.90911166]\n",
      " [ 0.97671802  1.41704229  0.79882862  1.59107523  0.05293342  1.68086527\n",
      "   0.90911166]\n",
      " [ 0.1913294  -0.72749202 -0.07660001 -0.89497982  0.61012728  0.27045463\n",
      "   0.90911166]\n",
      " [-0.59405923 -0.39756367 -0.95202863 -0.39776881  0.05293342 -0.98884057\n",
      "  -1.09997489]\n",
      " [-1.03038624 -0.8924562  -0.95202863 -1.88940184 -1.06145431 -1.61009288\n",
      "  -1.09997489]\n",
      " [-1.55397866 -1.22238456 -0.95202863 -1.39219083 -1.61864817 -1.20711841\n",
      "  -1.09997489]\n",
      " [-1.90304027 -1.38734873 -1.82745726 -1.39219083 -2.17584203 -1.72762709\n",
      "  -1.09997489]\n",
      " [-0.41952842 -1.22238456 -1.82745726 -0.39776881 -0.50426044 -0.11572923\n",
      "   0.90911166]\n",
      " [ 1.06398342  0.92214975  0.79882862  0.59665321  0.05293342  1.2778908\n",
      "   0.90911166]\n",
      " [ 0.1913294  -0.39756367  0.79882862  0.59665321  1.16732114  0.10254861\n",
      "   0.90911166]\n",
      " [-1.37944785 -0.8924562  -0.07660001 -0.89497982 -1.61864817 -0.78735334\n",
      "   0.90911166]\n",
      " [-0.85585544 -0.39756367  0.79882862 -0.39776881 -0.50426044 -1.10637479\n",
      "  -1.09997489]\n",
      " [-1.11765165 -0.06763531 -0.07660001  0.0994422  -0.50426044 -1.24069961\n",
      "  -1.09997489]\n",
      " [-1.64124406 -1.71727709 -0.95202863 -1.39219083 -0.50426044 -2.33208879\n",
      "  -1.09997489]\n",
      " [-1.03038624 -1.88224127  0.79882862 -0.39776881  1.16732114 -0.5690755\n",
      "  -1.09997489]\n",
      " [-0.24499762 -1.38734873  0.79882862  0.0994422   1.16732114  0.22008283\n",
      "   0.90911166]\n",
      " [ 0.10406399 -1.05742038  1.67425725  0.0994422   1.724515    0.30403584\n",
      "   0.90911166]\n",
      " [ 0.54039101  0.42725722  0.79882862  0.59665321  1.724515    0.47194187\n",
      "   0.90911166]\n",
      " [ 0.80218721  1.08711393  0.79882862  0.59665321  0.05293342  0.94207874\n",
      "   0.90911166]\n",
      " [ 0.2785948   0.42725722  1.67425725  0.59665321  0.61012728  1.12677537\n",
      "   0.90911166]\n",
      " [-0.50679383 -0.72749202 -0.07660001 -1.39219083  0.61012728 -0.85451575\n",
      "  -1.09997489]\n",
      " [ 0.88945262  1.41704229  0.79882862  0.59665321  1.16732114  1.47937803\n",
      "   0.90911166]\n",
      " [-0.07046681 -0.8924562  -0.95202863  0.59665321  0.05293342 -0.75377213\n",
      "  -1.09997489]\n",
      " [-0.76859003 -0.39756367  0.79882862 -0.39776881 -1.06145431 -1.08958419\n",
      "   0.90911166]\n",
      " [-1.46671326 -1.05742038 -0.07660001  0.0994422  -1.06145431 -1.20711841\n",
      "  -1.09997489]\n",
      " [-1.11765165 -0.56252785 -0.07660001 -0.89497982 -1.61864817 -0.80414394\n",
      "  -1.09997489]\n",
      " [-0.68132463 -0.39756367  0.79882862  0.0994422  -1.61864817 -0.70340033\n",
      "  -1.09997489]\n",
      " [ 0.10406399 -0.72749202 -0.07660001  0.59665321  1.16732114 -0.18289164\n",
      "   0.90911166]\n",
      " [ 0.71492181  0.42725722  0.79882862  1.09386422  0.61012728  0.60626669\n",
      "   0.90911166]\n",
      " [ 0.3658602  -0.8924562  -0.07660001  0.0994422   0.61012728  0.6902197\n",
      "   0.90911166]\n",
      " [ 0.54039101 -0.06763531  0.79882862 -0.39776881 -1.06145431 -0.19968224\n",
      "   0.90911166]\n",
      " [ 0.97671802  0.92214975  0.79882862  0.59665321 -1.06145431  0.28724524\n",
      "   0.90911166]\n",
      " [-1.11765165 -0.72749202  1.67425725  1.59107523 -0.50426044 -1.139956\n",
      "  -1.09997489]\n",
      " [ 0.01679859 -0.23259949 -0.07660001  0.0994422  -0.50426044 -1.19032781\n",
      "   0.90911166]\n",
      " [-0.50679383 -1.05742038 -0.95202863 -0.89497982  0.05293342 -0.43475068\n",
      "   0.90911166]\n",
      " [ 0.1913294  -0.8924562  -0.07660001 -0.89497982 -1.06145431 -0.38437887\n",
      "  -1.09997489]\n",
      " [ 0.88945262  1.25207811  0.79882862  0.0994422   0.61012728  0.90849754\n",
      "  -1.09997489]\n",
      " [ 0.4531256   0.75718558 -0.07660001 -0.39776881  0.61012728  0.0353862\n",
      "   0.90911166]\n",
      " [-1.29218245  0.42725722 -0.07660001  0.59665321  1.16732114 -0.16610104\n",
      "  -1.09997489]\n",
      " [-0.85585544 -0.39756367 -0.95202863 -0.89497982  1.16732114 -0.80414394\n",
      "   0.90911166]\n",
      " [-1.72850946 -1.38734873  0.79882862 -0.39776881  0.05293342 -1.32465263\n",
      "  -1.09997489]\n",
      " [-1.64124406 -1.05742038  0.79882862 -0.89497982  1.16732114 -1.52613986\n",
      "   0.90911166]\n",
      " [-1.46671326 -2.04720544 -0.95202863 -0.39776881 -2.17584203 -0.63623792\n",
      "   0.90911166]\n",
      " [-1.37944785 -1.38734873 -0.07660001 -0.89497982 -1.61864817 -0.25005405\n",
      "   0.90911166]\n",
      " [ 1.32577963  0.09732886  1.67425725  1.09386422  0.61012728  0.70701031\n",
      "   0.90911166]\n",
      " [ 1.76210664  1.58200646  1.67425725  1.59107523  1.724515    2.13421154\n",
      "   0.90911166]\n",
      " [ 1.15124883  2.076899    1.67425725  1.09386422  1.724515    1.61370285\n",
      "   0.90911166]\n",
      " [-0.41952842 -0.72749202  0.79882862  0.59665321  1.724515   -0.28363526\n",
      "  -1.09997489]\n",
      " [ 0.88945262  0.92214975  0.79882862  1.09386422  1.16732114  0.74059151\n",
      "  -1.09997489]]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.62765641  0.26229304 -0.07660001  0.0994422  -0.50426044  0.57268548\n",
      "  0.90911166]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.7531 - mean_absolute_error: 1.2975\n",
      "Epoch 2/80\n",
      "400/400 [==============================] - 0s 111us/step - loss: 0.5779 - mean_absolute_error: 0.7368\n",
      "Epoch 3/80\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1333 - mean_absolute_error: 0.3365\n",
      "Epoch 4/80\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0156 - mean_absolute_error: 0.1041\n",
      "Epoch 5/80\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0058 - mean_absolute_error: 0.0573\n",
      "Epoch 6/80\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0055 - mean_absolute_error: 0.0558\n",
      "Epoch 7/80\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0053 - mean_absolute_error: 0.0548\n",
      "Epoch 8/80\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0050 - mean_absolute_error: 0.0519\n",
      "Epoch 9/80\n",
      "400/400 [==============================] - 0s 104us/step - loss: 0.0050 - mean_absolute_error: 0.0519\n",
      "Epoch 10/80\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0048 - mean_absolute_error: 0.0499\n",
      "Epoch 11/80\n",
      "400/400 [==============================] - 0s 54us/step - loss: 0.0047 - mean_absolute_error: 0.0502\n",
      "Epoch 12/80\n",
      "400/400 [==============================] - 0s 64us/step - loss: 0.0045 - mean_absolute_error: 0.0486\n",
      "Epoch 13/80\n",
      "400/400 [==============================] - 0s 45us/step - loss: 0.0046 - mean_absolute_error: 0.0486\n",
      "Epoch 14/80\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0044 - mean_absolute_error: 0.0474\n",
      "Epoch 15/80\n",
      "400/400 [==============================] - 0s 94us/step - loss: 0.0044 - mean_absolute_error: 0.0469\n",
      "Epoch 16/80\n",
      "400/400 [==============================] - 0s 91us/step - loss: 0.0045 - mean_absolute_error: 0.0475\n",
      "Epoch 17/80\n",
      "400/400 [==============================] - 0s 91us/step - loss: 0.0044 - mean_absolute_error: 0.0471\n",
      "Epoch 18/80\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0044 - mean_absolute_error: 0.0476\n",
      "Epoch 19/80\n",
      "400/400 [==============================] - 0s 61us/step - loss: 0.0041 - mean_absolute_error: 0.0472\n",
      "Epoch 20/80\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.0044 - mean_absolute_error: 0.0478\n",
      "Epoch 21/80\n",
      "400/400 [==============================] - 0s 95us/step - loss: 0.0044 - mean_absolute_error: 0.0482\n",
      "Epoch 22/80\n",
      "400/400 [==============================] - 0s 89us/step - loss: 0.0043 - mean_absolute_error: 0.0464\n",
      "Epoch 23/80\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0043 - mean_absolute_error: 0.0465\n",
      "Epoch 24/80\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0042 - mean_absolute_error: 0.0471\n",
      "Epoch 25/80\n",
      "400/400 [==============================] - 0s 63us/step - loss: 0.0042 - mean_absolute_error: 0.0475\n",
      "Epoch 26/80\n",
      "400/400 [==============================] - 0s 107us/step - loss: 0.0043 - mean_absolute_error: 0.0458\n",
      "Epoch 27/80\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0043 - mean_absolute_error: 0.0467\n",
      "Epoch 28/80\n",
      "400/400 [==============================] - 0s 128us/step - loss: 0.0042 - mean_absolute_error: 0.0466\n",
      "Epoch 29/80\n",
      "400/400 [==============================] - 0s 104us/step - loss: 0.0043 - mean_absolute_error: 0.0470\n",
      "Epoch 30/80\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0043 - mean_absolute_error: 0.0469\n",
      "Epoch 31/80\n",
      "400/400 [==============================] - 0s 112us/step - loss: 0.0042 - mean_absolute_error: 0.0473\n",
      "Epoch 32/80\n",
      "400/400 [==============================] - 0s 98us/step - loss: 0.0042 - mean_absolute_error: 0.0468\n",
      "Epoch 33/80\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.0042 - mean_absolute_error: 0.0466\n",
      "Epoch 34/80\n",
      "400/400 [==============================] - 0s 49us/step - loss: 0.0042 - mean_absolute_error: 0.0461\n",
      "Epoch 35/80\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0041 - mean_absolute_error: 0.0464\n",
      "Epoch 36/80\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0043 - mean_absolute_error: 0.0472\n",
      "Epoch 37/80\n",
      "400/400 [==============================] - 0s 54us/step - loss: 0.0043 - mean_absolute_error: 0.0466\n",
      "Epoch 38/80\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.0043 - mean_absolute_error: 0.0466\n",
      "Epoch 39/80\n",
      "400/400 [==============================] - 0s 64us/step - loss: 0.0043 - mean_absolute_error: 0.0470\n",
      "Epoch 40/80\n",
      "400/400 [==============================] - 0s 99us/step - loss: 0.0042 - mean_absolute_error: 0.0475\n",
      "Epoch 41/80\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0042 - mean_absolute_error: 0.0466\n",
      "Epoch 42/80\n",
      "400/400 [==============================] - 0s 93us/step - loss: 0.0042 - mean_absolute_error: 0.0468\n",
      "Epoch 43/80\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0043 - mean_absolute_error: 0.0470\n",
      "Epoch 44/80\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0042 - mean_absolute_error: 0.0469\n",
      "Epoch 45/80\n",
      "400/400 [==============================] - 0s 61us/step - loss: 0.0043 - mean_absolute_error: 0.0469\n",
      "Epoch 46/80\n",
      "400/400 [==============================] - 0s 47us/step - loss: 0.0042 - mean_absolute_error: 0.0462\n",
      "Epoch 47/80\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.0044 - mean_absolute_error: 0.0480\n",
      "Epoch 48/80\n",
      "400/400 [==============================] - 0s 97us/step - loss: 0.0043 - mean_absolute_error: 0.0463\n",
      "Epoch 49/80\n",
      "400/400 [==============================] - 0s 66us/step - loss: 0.0043 - mean_absolute_error: 0.0472\n",
      "Epoch 50/80\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0043 - mean_absolute_error: 0.0463\n",
      "Epoch 51/80\n",
      "400/400 [==============================] - 0s 64us/step - loss: 0.0042 - mean_absolute_error: 0.0473\n",
      "Epoch 52/80\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0041 - mean_absolute_error: 0.0459\n",
      "Epoch 53/80\n",
      "400/400 [==============================] - 0s 59us/step - loss: 0.0042 - mean_absolute_error: 0.0467\n",
      "Epoch 54/80\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0043 - mean_absolute_error: 0.0473\n",
      "Epoch 55/80\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0043 - mean_absolute_error: 0.0466\n",
      "Epoch 56/80\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0042 - mean_absolute_error: 0.0469\n",
      "Epoch 57/80\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0042 - mean_absolute_error: 0.0462\n",
      "Epoch 58/80\n",
      "400/400 [==============================] - 0s 59us/step - loss: 0.0042 - mean_absolute_error: 0.0466\n",
      "Epoch 59/80\n",
      "400/400 [==============================] - 0s 56us/step - loss: 0.0043 - mean_absolute_error: 0.0463\n",
      "Epoch 60/80\n",
      "400/400 [==============================] - 0s 66us/step - loss: 0.0043 - mean_absolute_error: 0.0475\n",
      "Epoch 61/80\n",
      "400/400 [==============================] - 0s 108us/step - loss: 0.0042 - mean_absolute_error: 0.0462\n",
      "Epoch 62/80\n",
      "400/400 [==============================] - 0s 101us/step - loss: 0.0042 - mean_absolute_error: 0.0465\n",
      "Epoch 63/80\n",
      "400/400 [==============================] - 0s 103us/step - loss: 0.0044 - mean_absolute_error: 0.0473\n",
      "Epoch 64/80\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0041 - mean_absolute_error: 0.0455\n",
      "Epoch 65/80\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0043 - mean_absolute_error: 0.0471\n",
      "Epoch 66/80\n",
      "400/400 [==============================] - 0s 51us/step - loss: 0.0042 - mean_absolute_error: 0.0462\n",
      "Epoch 67/80\n",
      "400/400 [==============================] - 0s 42us/step - loss: 0.0041 - mean_absolute_error: 0.0462\n",
      "Epoch 68/80\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0043 - mean_absolute_error: 0.0465\n",
      "Epoch 69/80\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0042 - mean_absolute_error: 0.0465\n",
      "Epoch 70/80\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0043 - mean_absolute_error: 0.0476\n",
      "Epoch 71/80\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.0042 - mean_absolute_error: 0.0471\n",
      "Epoch 72/80\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.0042 - mean_absolute_error: 0.0456\n",
      "Epoch 73/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 77us/step - loss: 0.0042 - mean_absolute_error: 0.0471\n",
      "Epoch 74/80\n",
      "400/400 [==============================] - 0s 54us/step - loss: 0.0042 - mean_absolute_error: 0.0460\n",
      "Epoch 75/80\n",
      "400/400 [==============================] - 0s 40us/step - loss: 0.0043 - mean_absolute_error: 0.0458\n",
      "Epoch 76/80\n",
      "400/400 [==============================] - 0s 59us/step - loss: 0.0042 - mean_absolute_error: 0.0471\n",
      "Epoch 77/80\n",
      "400/400 [==============================] - 0s 64us/step - loss: 0.0041 - mean_absolute_error: 0.0455\n",
      "Epoch 78/80\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0043 - mean_absolute_error: 0.0474\n",
      "Epoch 79/80\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.0042 - mean_absolute_error: 0.0464\n",
      "Epoch 80/80\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0042 - mean_absolute_error: 0.0469\n",
      "100/100 [==============================] - 0s 987us/step\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "#Training on Entire Data\n",
    "model.fit(train_data, train_labels, epochs = 80, batch_size = 16, verbose = 1)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76928246]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([a,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76928246]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([a,]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
